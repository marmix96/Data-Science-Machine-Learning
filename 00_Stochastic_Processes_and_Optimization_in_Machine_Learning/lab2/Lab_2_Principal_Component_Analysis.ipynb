{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s_xjbOW-TkC3"
   },
   "source": [
    "<h1><b><i>Principal Component Analysis</i> (<i>PCA</i>) </b></h1>\n",
    "\n",
    "<p>Στην άσκηση αυτή θα μελετήσετε τον αλγόριθμο <b><i>ανάλυσης σε κύριες συνιστώσες</i></b> (<b><i>Principal Component Analysis</i></b>, <b><i>PCA</i></b>), υλοποιημένο σύμφωνα με τη <b><i>μέθοδο συνδιακύμανσης</i></b> (<b><i>covariance method</i></b>). Για να κατανοήσετε τη χρησιμότητα της μεθόδου θα εκπαιδεύσετε και θα αξιολογήσετε την ακρίβεια ενός μοντέλου <b><i>logistic regression</i></b> για ένα dataset πριν και μετά την εφαρμογή του αλγορίθμου <b><i>PCA</i></b>. Περισσότερες πληροφορίες για τη μέθοδο αυτή μπορείτε να αναζητήσετε <a href=\"https://ourarchive.otago.ac.nz/handle/10523/7534\">εδώ</a>.</p>\n",
    "\n",
    "<p>Η άσκηση περιλαμβάνει <b><i>δύο</i></b> προγράμματα <i>Python</i>: (a) το πρώτο δέχεται ένα dataset σε μορφή .<i>csv</i>, εφαρμόζει τον αλγόριθμο <b><i>PCA</i></b> και δημιουργεί το αρχείο <b><i>foo.csv</i></b> με το μετασχηματισμένο dataset, όπως προκύπτει από τις κύριες συνιστώσες που επέλεξε ο χρήστης να διατηρήσει, (b) το δεύτερο δέχεται ένα αρχείο σε μορφή .<i>csv</i>, διαχωρίζει το dataset σε <i>training</i> και <i>test set</i>, εκπαιδεύει ένα μοντέλο <b><i>logistic regression</i></b>, χρησιμοποιώντας το <i>training set</i> και υπολογίζει τον αριθμό των σφαλμάτων του μοντέλου πάνω στο <i>test set</i>.</p>\n",
    "\n",
    "<p>Το dataset που θα χρησιμοποιήσετε παρέχεται σε δύο μορφές: (a) <b><i><a href=\"https://raw.githubusercontent.com/nkostopoulos/StochasticsLabPublic/master/lab2/demo3a.csv\">demo3a.csv</a></i></b> και (b) <b><i><a href=\"https://github.com/nkostopoulos/StochasticsLabPublic/blob/master/lab2/demo3b.csv\">demo3b.csv</a></i></b>, το οποίο δεν περιλαμβάνει την πρώτη στήλη του <b><i><a href=\"https://raw.githubusercontent.com/nkostopoulos/StochasticsLabPublic/master/lab2/demo3a.csv\">demo3a.csv</a></i></b>, δηλαδή τα <i>labels</i> που αντιστοιχούν σε κάθε είσοδο. Τα datasets αυτά αποτελούν απλοποιημένη μορφή του dataset που μπορεί να βρεθεί <a href=\"https://archive.ics.uci.edu/ml/datasets/wine\">εδώ</a>.</p>\n",
    "\n",
    "<h3><b><i>Ανάλυση σε Κύριες Συνιστώσες</i></b></h3>\n",
    "<p>Αρχικά, θα φορτώσετε τις βιβλιοθήκες που απαιτούνται για το πρόγραμμα που θα αναλύσει το dataset <b><i><a href=\"https://github.com/nkostopoulos/StochasticsLabPublic/blob/master/lab2/demo3b.csv\">demo3b.csv</a></i></b> στις κύριες συνιστώσες του.</p>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "KDcaQZ2ofeum",
    "outputId": "68e1a244-2720-43f2-d7f0-524f5ef882ef"
   },
   "outputs": [],
   "source": [
    "#https://machinelearningmastery.com/calculate-principal-component-analysis-scratch-python/\n",
    "from numpy import genfromtxt\n",
    "from numpy import mean\n",
    "from numpy import cov\n",
    "from numpy.linalg import eig\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pMilxe9Uf-WT"
   },
   "source": [
    "<p>Στη συνέχεια, θα φορτώσετε το dataset <b><i></i></b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k92Gv9dwftZp"
   },
   "outputs": [],
   "source": [
    "data = genfromtxt('demo3b.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ydl-AyxahG2b"
   },
   "source": [
    "<p>Έπειτα, θα υπολογίσετε το μέσο όρο κάθε στήλης (feature) του dataset και θα κανονικοποιήσετε κάθε feature με αυτόν</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QU4TQXw2g4xF"
   },
   "outputs": [],
   "source": [
    "M = mean(data.T, axis=1)\n",
    "data_normal = data - M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BYWD8ozQh-h8"
   },
   "source": [
    "<p>Στη συνέχεια, θα υπολογίσετε το <b><i>πίνακα συνδιακύμανσης</i></b> (<b><i>covariance matrix</i></b>) για το dataset</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 918
    },
    "colab_type": "code",
    "id": "N3B6Pw6diHxe",
    "outputId": "f77a72d3-6b85-454f-e023-66ed6ca7825f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The covariance matrix of the normalized data is the following: \n",
      "[[ 7.89911157e-01  1.64350328e-02  5.03965534e-02 -1.39557561e+00\n",
      "   4.51870543e+00  2.35123047e-01  3.56524806e-01 -2.92133512e-02\n",
      "   9.15320632e-02  1.07205560e+00  3.92238044e-03  1.22678110e-01\n",
      "   2.36909466e+02]\n",
      " [ 1.64350328e-02  7.74344335e-01  3.18039952e-02  4.24165474e-01\n",
      "  -2.21434109e-01  1.44160704e-02  3.75581395e-02  5.34385808e-03\n",
      "   6.47891175e-02 -1.54797734e-01 -6.06599761e-02  6.96007454e-02\n",
      "  -3.33629219e+01]\n",
      " [ 5.03965534e-02  3.18039952e-02  8.83052117e-02  3.73006798e-01\n",
      "   1.40136434e+00  4.12452594e-02  8.26573643e-02  5.81539654e-03\n",
      "   1.24709839e-02  1.22397007e-01  2.06346094e-03  3.02871079e-02\n",
      "   3.18556160e+01]\n",
      " [-1.39557561e+00  4.24165474e-01  3.73006798e-01  1.15631181e+01\n",
      "  -6.46193798e+00 -4.24464222e-01 -4.52046512e-01  1.24282469e-01\n",
      "  -1.77910614e-01 -2.39565069e+00 -2.05387955e-02 -1.02069171e-03\n",
      "  -5.11872284e+02]\n",
      " [ 4.51870543e+00 -2.21434109e-01  1.40136434e+00 -6.46193798e+00\n",
      "   2.36586822e+02  2.55096899e+00  2.89720930e+00 -3.57263566e-01\n",
      "   2.30737209e+00  8.63970543e+00  1.85996899e-01  9.56255814e-01\n",
      "   2.31515659e+03]\n",
      " [ 2.35123047e-01  1.44160704e-02  4.12452594e-02 -4.24464222e-01\n",
      "   2.55096899e+00  2.97453936e-01  3.40611628e-01 -2.64587657e-02\n",
      "   1.30694305e-01  5.23527370e-01 -7.63816339e-04  1.28195856e-01\n",
      "   9.73171139e+01]\n",
      " [ 3.56524806e-01  3.75581395e-02  8.26573643e-02 -4.52046512e-01\n",
      "   2.89720930e+00  3.40611628e-01  5.44297674e-01 -2.88767442e-02\n",
      "   2.16111628e-01  8.48084496e-01 -8.24186047e-04  1.88436434e-01\n",
      "   1.41942171e+02]\n",
      " [-2.92133512e-02  5.34385808e-03  5.81539654e-03  1.24282469e-01\n",
      "  -3.57263566e-01 -2.64587657e-02 -2.88767442e-02  1.18999463e-02\n",
      "  -1.98501670e-02 -4.97212642e-02  9.44753727e-04 -2.42901670e-02\n",
      "  -1.26918819e+01]\n",
      " [ 9.15320632e-02  6.47891175e-02  1.24709839e-02 -1.77910614e-01\n",
      "   2.30737209e+00  1.30694305e-01  2.16111628e-01 -1.98501670e-02\n",
      "   2.91137680e-01  2.39266834e-01 -9.77493143e-04  8.78196959e-02\n",
      "   5.22928014e+01]\n",
      " [ 1.07205560e+00 -1.54797734e-01  1.22397007e-01 -2.39565069e+00\n",
      "   8.63970543e+00  5.23527370e-01  8.48084496e-01 -4.97212642e-02\n",
      "   2.39266834e-01  2.64316778e+00  2.68330829e-03  1.60809159e-01\n",
      "   4.44340177e+02]\n",
      " [ 3.92238044e-03 -6.06599761e-02  2.06346094e-03 -2.05387955e-02\n",
      "   1.85996899e-01 -7.63816339e-04 -8.24186047e-04  9.44753727e-04\n",
      "  -9.77493143e-04  2.68330829e-03  2.84562519e-02 -8.13836136e-03\n",
      "   6.93777746e+00]\n",
      " [ 1.22678110e-01  6.96007454e-02  3.02871079e-02 -1.02069171e-03\n",
      "   9.56255814e-01  1.28195856e-01  1.88436434e-01 -2.42901670e-02\n",
      "   8.78196959e-02  1.60809159e-01 -8.13836136e-03  2.25782952e-01\n",
      "   3.83903673e+01]\n",
      " [ 2.36909466e+02 -3.33629219e+01  3.18556160e+01 -5.11872284e+02\n",
      "   2.31515659e+03  9.73171139e+01  1.41942171e+02 -1.26918819e+01\n",
      "   5.22928014e+01  4.44340177e+02  6.93777746e+00  3.83903673e+01\n",
      "   1.24265433e+05]]\n"
     ]
    }
   ],
   "source": [
    "covariance = cov(data_normal.T)\n",
    "print(\"The covariance matrix of the normalized data is the following: \")\n",
    "print(covariance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rFxfxGxbiPsm"
   },
   "source": [
    "<p>Το επόμενο βήμα είναι να υπολογίσετε τις <b><i>ιδιοτιμές</i></b> (<b><i>eigenvalues</i></b>) και τα <b><i>ιδιοδιανύσματα</i></b> (<b><i>eigenvectors</i></b>) του dataset.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "nyqu1myLieP3",
    "outputId": "814fe6ee-0258-4232-82f4-0a35b7e3d06a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The eigenvalues of the normalized data are the following: \n",
      "[1.24313073e+05 1.93456026e+02 9.50168321e+00 1.32500169e+00\n",
      " 8.10595669e-01 4.51081713e-01 2.69157831e-01 1.60993380e-01\n",
      " 1.11100343e-01 6.13399000e-03 2.19782528e-02 3.20312852e-02\n",
      " 5.87421686e-02]\n"
     ]
    }
   ],
   "source": [
    "values, vectors = eig(covariance)\n",
    "print(\"The eigenvalues of the normalized data are the following: \")\n",
    "print(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "51_NKEP2imoW"
   },
   "source": [
    "<p>Στη συνέχεια, θα επιλέξετε τις πιο σημαντικές <b><i>ιδιοτιμές</i></b> και θα προσαρμόσετε αντίστοιχα τα <b><i>ιδιοδιανύσματα</i></b> του dataset.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "Dee3ENf1i4Lx",
    "outputId": "7617d250-65bd-4ab0-a4d9-2dea8c9dfd03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most important eigenvalues are the following: \n",
      "[1.24313073e+05 1.93456026e+02 9.50168321e+00]\n",
      "The most important eigenvectors are the following: \n",
      "[[-1.90615566e-03 -4.75319302e-04 -4.70065618e-02  2.25255930e-01\n",
      "   9.82089183e-02 -2.20758056e-01 -8.52483156e-01 -3.65140031e-01\n",
      "  -1.65925760e-01 -5.62139324e-03 -2.07811823e-02  2.48378617e-02\n",
      "  -8.18675258e-04]\n",
      " [ 2.68379014e-04 -2.11118304e-03  3.21935310e-02  1.25115825e-01\n",
      "   9.16405147e-01 -3.07909300e-01  1.86306127e-01  7.26209733e-02\n",
      "  -1.81047372e-02 -1.16925805e-02  8.44468784e-02 -2.41209813e-02\n",
      "   2.31770029e-02]\n",
      " [-2.56407459e-04 -4.21644285e-03  5.19948847e-02  4.67286333e-02\n",
      "   2.01302236e-02 -3.45064791e-03 -1.57617050e-02  1.52544206e-01\n",
      "  -7.18891029e-02 -1.38330530e-01 -6.68720003e-02  6.75337422e-01\n",
      "  -6.97354965e-01]]\n"
     ]
    }
   ],
   "source": [
    "new_values = values[0:3]\n",
    "print(\"The most important eigenvalues are the following: \")\n",
    "print(new_values)\n",
    "new_vectors = vectors[0:3]\n",
    "print(\"The most important eigenvectors are the following: \")\n",
    "print(new_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6IVdHr-Ti-O5"
   },
   "source": [
    "<p>Τώρα, θα εφαρμόσετε τα νέα <b><i>ιδιοδιανύσματα</i></b> στο παλιό dataset για να πάρετε το νέο, μειωμένο σε μέγεθος dataset.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HtJouKmSjPbD"
   },
   "outputs": [],
   "source": [
    "new_data = new_vectors.dot(data_normal.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o5B93KQ3jTpf"
   },
   "source": [
    "<p>Να αποθηκεύσετε το νέο dataset σε ένα αρχείο <i>csv</i>.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W1uY6kFWjflf"
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"foo.csv\", new_data.T, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8u085fpWjnPD"
   },
   "source": [
    "<h4><b><i>Ερωτήσεις</i></b></h4>\n",
    "<ul>\n",
    "<li>Να μελετήσετε το παραπάνω πρόγραμμα και να περιγράψετε, σύντομα, τα βήματα που ακολουθεί ο αλγόριθμος <b><i>PCA</i></b>, υλοποιημένος με τη μέθοδο <b><i>covariance</i></b>. Να συμπεριλάβετε και τις μαθηματικές πράξεις.</li>\n",
    "<li>Να εφαρμόσετε τον αλγόριθμο <b><i>PCA</i></b> πάνω στα δεδομένα του αρχείου <i><a href=\"https://github.com/nkostopoulos/StochasticsLabPublic/blob/master/lab2/demo3b.csv\">demo3b.csv</a></i>. Στη συνέχεια, να καταγράψετε τον <i>πίνακα συνδιακύμανσης</i> του dataset και τις ιδιοτιμές του πίνακα αυτού. Τι υποδηλώνουν οι θετικές και τι οι αρνητικές τιμές του <i>πίνακα συνδιακύμανσης</i>; Να διατάξετε τις <i>ιδιοτιμές</i> σε φθίνουσα σειρά. Τι παρατηρείτε για τις τρεις πρώτες σε σχέση με τις υπόλοιπες; Πόσες <i>κύριες συνιστώσες</i> επιλέγει να διατηρήσει ο αλγόριθμος;</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Τα βήματα που ακολουθεί ο αλγόριθμος είναι:\\\n",
    "$\\begin{align}\n",
    "\\mathrm{normal\\ data} &= \\mathrm{data} - \\mathrm{mean(data)}\\\\\n",
    "C &= \\mathrm{Cov}[\\mathrm{normal\\ data}]\\\\\n",
    "\\mathrm{new\\ data} &= \\Lambda_m \\cdot \\mathrm{normal\\ data}^\\top\n",
    "\\end{align}$\n",
    "\n",
    " Όπου $\\Lambda_i = \\mathrm{diag}(\\lambda_1, \\dots, \\lambda_i)$ με $\\lambda_1 \\ge \\lambda_2 \\ge \\dots \\ge \\lambda_i$, όπου $m$ είναι το πλήθος των κύριων συνιστωσών που επιλέξαμε να κρατήσουμε (δηλαδή το $\\Lambda_m$ αντιστοιχεί στο new_vectors).\n",
    "- Το πρόσημο μιας τιμής του πίνακα συνδιακύμανσης υποδηλώνει τη συσχέτιση των μεταβλητών. Θετικό πρόσημο σημαίνει ότι αύξηση της μίας συνεπάγεται και αύξηση της άλλης, δηλαδή οτι μεταβάλλονται με αντίστοιχο τρόπο. Παρατηρώντας το values, αντιλαμβάνομαστε ότι οι 3 πρώτες ιδιοτιμές είναι σαφώς μεγαλύτερες από τις υπόλοιπες και για αυτό ο αλγόριθμος επιλέγει να κρατήσει 3 κύριες συνιστώσες."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DBRxVL9BmqGw"
   },
   "source": [
    "<h3><b><i>Logistic Regression</i></b></h3>\n",
    "\n",
    "<p>Αρχικά, θα φορτώσετε τις απαραίτητες βιβλιοθήκες.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "colab_type": "code",
    "id": "MiGjiOEQnpwn",
    "outputId": "816c0f5e-49cd-45db-beb2-1725ed25fbd5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from time import perf_counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JnNo_v4Jn3gn"
   },
   "source": [
    "Στη συνέχεια, θα φορτώσετε τα datasets που θα χρησιμοποιηθούν για την εκπαίδευση του μοντέλου <b><i>logistic regression</i></b>. Στην πρώτη περίπτωση, θα εκπαιδεύσετε το μοντέλο, χρησιμοποιώντας το αρχείο <i><a href=\"https://raw.githubusercontent.com/nkostopoulos/StochasticsLabPublic/master/lab2/demo3a.csv\">demo3a.csv</a></i>. Στη δεύτερη περίπτωση, θα φορτώσετε το αρχείο <i>foo.csv</i> που πήρατε ως έξοδο από το προηγούμενο τμήμα κώδικα της άσκησης (<i>Ανάλυση σε Κύριες Συνιστώσες</i>), προσθέτοντας στην πρώτη στήλη του αρχείου τα labels που υπάρχουν στην πρώτη στήλη του αρχείου <a href=\"https://raw.githubusercontent.com/nkostopoulos/StochasticsLabPublic/master/lab2/demo3a.csv\"><i>demo3a.csv</i></a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7cJDDmjxpSTT"
   },
   "outputs": [],
   "source": [
    "#df = pd.read_csv(\"https://raw.githubusercontent.com/nkostopoulos/StochasticsLabPublic/master/lab2/demo3a.csv\")\n",
    "df1 = pd.read_csv(\"foo.csv\",    header=None)\n",
    "df2 = pd.read_csv(\"demo3a.csv\", header=None)\n",
    "df1.insert(0, \"Label\", df2.iloc[:, 0])\n",
    "models = [\"demo3a-NO PCA\", \"demo3a-PCA with 1 component\", \"demo3a-PCA with 2 components\", \"foo-Custom PCA with 3 components\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nyQn9Hjapdjj"
   },
   "source": [
    "<p>Έπειτα, θα χωρίσετε το dataset σε <i>training</i> και <i>test set</i>.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Για ευκολία θα χρησιμοποιήσουμε ένα loop για την υλοποίηση της διαδικασίας μιας και είναι σχεδόν το ίδιο κάθε φορά."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NuWbSbVwpWUe"
   },
   "outputs": [],
   "source": [
    "total_errors = []\n",
    "fit_times = []\n",
    "for i, df in enumerate([df2, df2, df2, df1]):\n",
    "    # Separate the input features from the target variable\n",
    "    x = df.iloc[:,1:].values\n",
    "    y = df.iloc[:,0].values\n",
    "\n",
    "    # Split the dataset into train and test set\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size = 0.2)\n",
    "    if i in [1,2]: # checking PCA with 1 and 2 components\n",
    "        scaler = StandardScaler() # always scale before PCA\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test  = scaler.transform(X_test) \n",
    "        pca    = PCA(n_components = i)\n",
    "        X_train = pca.fit_transform(X_train)\n",
    "        X_test  = pca.transform(X_test)\n",
    "    classifier = LogisticRegression(max_iter = 1000)\n",
    "    t1_start = perf_counter() \n",
    "    classifier.fit(X_train, Y_train)\n",
    "    t1_stop = perf_counter()\n",
    "    \n",
    "    # Get the predictions on the test set\n",
    "    prediction = classifier.predict(X_test)\n",
    "    \n",
    "    errors = 0\n",
    "    for index in range(0,len(prediction) - 1):\n",
    "        if prediction[index] != Y_test[index]:\n",
    "            errors += 1\n",
    "    total_errors.append(errors)\n",
    "    fit_times.append(t1_stop - t1_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NuWbSbVwpWUe"
   },
   "outputs": [],
   "source": [
    "total_errors = []\n",
    "fit_times = []\n",
    "for i, df in enumerate([df2, df2, df2, df1]):\n",
    "    # Separate the input features from the target variable\n",
    "    x = df.iloc[:,1:].values\n",
    "    y = df.iloc[:,0].values\n",
    "\n",
    "    # Split the dataset into train and test set\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size = 0.2)\n",
    "    if i in [1,2]: # checking PCA with 1 and 2 components\n",
    "        scaler = StandardScaler() # always scale before PCA\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test  = scaler.transform(X_test) \n",
    "        pca    = PCA(n_components = i)\n",
    "        X_train = pca.fit_transform(X_train)\n",
    "        X_test  = pca.transform(X_test)\n",
    "    classifier = LogisticRegression(max_iter = 1000)\n",
    "    t1_start = perf_counter() \n",
    "    classifier.fit(X_train, Y_train)\n",
    "    t1_stop = perf_counter()\n",
    "    \n",
    "    # Get the predictions on the test set\n",
    "    prediction = classifier.predict(X_test)\n",
    "    \n",
    "    errors = 0\n",
    "    for index in range(0,len(prediction) - 1):\n",
    "        if prediction[index] != Y_test[index]:\n",
    "            errors += 1\n",
    "    total_errors.append(errors)\n",
    "    fit_times.append(t1_stop - t1_start)\n",
    "    # print(\"{}:\\n Total errors on the test dataset: {}\\n Fit time: {:.4f}\\n\".format(models[i], errors, t1_stop - t1_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NuWbSbVwpWUe"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case</th>\n",
       "      <th>total_errors</th>\n",
       "      <th>fit_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>demo3a-NO PCA</td>\n",
       "      <td>1</td>\n",
       "      <td>0.052595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>demo3a-PCA with 1 component</td>\n",
       "      <td>3</td>\n",
       "      <td>0.002149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>demo3a-PCA with 2 components</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>foo-Custom PCA with 3 components</td>\n",
       "      <td>2</td>\n",
       "      <td>0.006151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               case  total_errors  fit_time\n",
       "0                     demo3a-NO PCA             1  0.052595\n",
       "1       demo3a-PCA with 1 component             3  0.002149\n",
       "2      demo3a-PCA with 2 components             0  0.001882\n",
       "3  foo-Custom PCA with 3 components             2  0.006151"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(zip(models, total_errors, fit_times)), columns = [\"case\", \"total_errors\", \"fit_time\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xRVRieelqVsA"
   },
   "source": [
    "<h4><b><i>Ερώτηση</i></b></h4>\n",
    "<p>Να εκτελέσετε παραπάνω τμήματα κώδικα με είσοδο τα αρχεία (a) <i><a href=\"https://raw.githubusercontent.com/nkostopoulos/StochasticsLabPublic/master/lab2/demo3a.csv\">demo3a.csv</a></i> και (b) <i>foo.csv</i>. Τι παρατηρείτε για την ακρίβεια του μοντέλου στις δύο περιπτώσεις; Δοκιμάστε και για την περίπτωση που κρατάμε (α) 1 και (β) 2 <i>κύριες συνιστώσες</i>. Τι παρατηρείτε;</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Γενικά παρατηρούμε σε όλες τις περιπτώσεις περίπου τα ίδια αποτελέσματα (μετά και από αρκετές δοκιμές). Η διαφορά στα λάθη που προκύπτουν ήταν το πολύ 3, με τα περισσότερα να εντοπίζονται κυρίως στην περίπτωση του PCA με 1 κύρια συνιστώσα. Αυτό εξηγείται από το γεγονός ότι η πρώτη ιδιοτιμή του πίνακα είναι πολύ μεγαλύτερη από τις υπόλοιπες. Η πρώτη είναι της τάξης του $10^5$, η δεύτερη της τάξης του $10^2$ και μετά αρχίζουν να πέφτουν πολύ περισσότερο. Συνεπώς, από μόνη της η πρώτη ιδιοτιμή είναι αρκετά επεξηγηματική για το σύνολο των δεδομένων μας."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gqPhHDExffku"
   },
   "source": [
    "<h3><b><i>Συμπληρωματικές Ερωτήσεις</i></b></h3>\n",
    "<ul>\n",
    "<li>Ποια είναι η χρησιμότητα του αλγορίθμου <b><i>PCA</i></b> ως προς τη δυνατότητα <i>οπτικοποίησης</i> (<i>visualization</i>) των δεδομένων του dataset;</li>\n",
    "<li>Ποια είναι η χρησιμότητα του αλγορίθμου <b><i>PCA</i></b> ως προς την ταχύτητα εκπαίδευσης του μοντέλου logistic regression; Να βασίσετε την απάντησή σας στα δύο παρακάτω τμήματα κώδικα.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Aποτελεί έναν από τους πίο δημοφιλείς τρόπους οπτικοποίησης δεδομένων, σε περιπτώσεις όπου ο αρχικός χώρος χαρακτηριστικών είναι αδύνατο να οπτικοποιηθεί. Η χρησιμότητα του αλγορίθμου PCA είναι ιδιαίτερα σημαντική, καθώς επιτυγχάνει μείωση της διάστασης του χώρου των χαρακτηριστικών και καθιστά εφικτή την οπτικοποίηση της προβολής του dataset στην κατεύθυνσης της μία, δύο ή τριών κύριων συνιστωσών, ώστε να αποκτά νόημα η εκάστοτε γραφική παράσταση που απεικονίζουμε. Για την λήψη αξιόπιστων αποτελεσμάτων επιθυμούμε οι πρώτες n κύριες συνιστώσες που επιλέγονται να \"ερμηνεύουν\" όσο το δυνατό μεγαλύτερο μέρος της συνολικής διασποράς των εκάστοτε δεδομένων.\n",
    "- Με βάση τα παραπάνω \"fit time\" παρατηρούμε ότι όσο λιγότερες κύριες συνιστώσες κρατάμε, τόσο μειώνεται ο απαιτούμενος χρόνος εκπαίδευσης, κάτι απόλυτα προφανές διότι έχουμε λιγότερες παραμέτρους προς εκπαίδευση."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Stochastic Processes & Optimization in Machine Learning: Principal Component Analysis (Lab 2)",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
