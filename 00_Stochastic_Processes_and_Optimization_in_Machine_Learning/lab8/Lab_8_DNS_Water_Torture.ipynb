{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kLUCLr2dsyWQ"
   },
   "source": [
    "<b><h1>DNS Water Torture σε Recursive DNS Servers</h1></b>\n",
    "\n",
    "<p align=\"justify\">Στην άσκηση αυτή, θα αναπτύξετε ένα μηχανισμό αντιμετώπισης επιθέσεων <i>DNS Water Torture</i> σε <i>Recursive DNS Servers</i> (δίνεται <a href=\"https://github.com/nkostopoulos/StochasticsLabPublic/blob/master/lab8/Lab8_theory.pdf\">υποστηρικτικό υλικό</a> για την άσκηση). Ουσιαστικά, το πρόβλημα αυτό είναι ένα πρόβλημα text classification που έγγειται στο διαχωρισμό ονομάτων DNS που είναι <i>έγκυρα (valid)</i> και <i>άκυρα (invalid)</i>. </p>\n",
    "\n",
    "<p align=\"justify\">Με τη βοήθεια του αλγορίθμου Naive Bayes Classifier, θα διαχωρίσετε τα prefixes των <i>ονομάτων DNS</i> σε <i>έγκυρα</i> και <i>άκυρα</i>. Στην άσκηση αυτή, ως <i>prefix</i> ορίζουμε το <i>πρώτο label</i> ενός <i>ονόματος DNS</i>. Για παράδειγμα, το prefix του ονόματος <a href=\"https://www.ntua.gr/el/\">www.ntua.gr</a> είναι το <i>www</i>, ενώ το prefix του ονόματος <a href=\"dolly.netmode.ece.ntua.gr\">dolly.netmode.ece.ntua.gr</a> είναι το <i>dolly</i>.</p>\n",
    "\n",
    "<p align=\"justify\">Ο αλγόριθμος θα εκπαιδευτεί με <u>έγκυρα ονόματα</u> (αρχείο <a href=\"https://raw.githubusercontent.com/nkostopoulos/StochasticsLabPublic/master/lab8/valid_training.txt\">valid_training.txt</a>) και άκυρα ονόματα (αρχείο <a href=\"https://raw.githubusercontent.com/nkostopoulos/StochasticsLabPublic/master/lab8/invalid_training.txt\">invalid_training</a>.txt). Η δοκιμή του θα γίνει στο <u>test set</u>, που περιλαμβάνει, επίσης, έγκυρα (αρχείο <a href=\"https://raw.githubusercontent.com/nkostopoulos/StochasticsLabPublic/master/lab8/valid_test.txt\">valid_test.txt</a>) και άκυρα (αρχείο <a href=\"https://raw.githubusercontent.com/nkostopoulos/StochasticsLabPublic/master/lab8/invalid_test.txt\">invalid_test.txt</a>) ονόμάτα.</p>\n",
    "\n",
    "<p align=\"justify\">Να απαντήσετε στις ακόλουθες ερωτήσεις:</p>\n",
    "<ul>\n",
    "<li>Ποια είναι η παραδοχή του αλγορίθμου <b><i>Naive Bayes Classifier</i></b>; Ποια είναι τα πλεονεκτήματα του αλγορίθμου;</li>\n",
    "<li>Να περιγράψετε σύντομα τη λειτουργία του αλγορίθμου <b><i>Naive Bayes Classifier</i></b>.</li>\n",
    "<li>Μελετήστε τα prefixes που περιλαμβάνονται στα αρχεία <a href=\"https://raw.githubusercontent.com/nkostopoulos/StochasticsLabPublic/master/lab8/valid_training.txt\">valid_training.txt</a> και <a href=\"https://raw.githubusercontent.com/nkostopoulos/StochasticsLabPublic/master/lab8/invalid_training.txt\">invalid_training.txt</a>. Σχολιάστε μερικές από τις βασικές διαφορές ανάμεσα στα prefixes των δύο αρχείων που θα μπορούσαν να φανούν χρήσιμες για το διαχωρισμό των έγκυρων και των άκυρων ονομάτων.</li>\n",
    "<li>Ποια είναι τα 7 features που έχουν επιλεχθεί στον κώδικα της άσκησης;</li>\n",
    "<li>Να εκτελέσετε τον κώδικα της άσκησης. Καταγράψετε και σχολιάστε την ακρίβεια του αλγορίθμου πάνω στο <i>test set</i> για τα valid και τα invalid names ξεχωριστά. Ποιο είναι το μέγεθος του <i>training set</i>; Πόση ώρα διήρκησε η εκπαίδευση του αλγορίθμου;</li>\n",
    "<li>Αφού εκτελέσετε τον κώδικα, θα παρατηρήσετε πως έχουν παραχθεί δύο αρχεία: <i>problematic_valid.txt</i> και <i>problematic_invalid.txt</i>. Μελετώντας τον κώδικα, γιατί πιστεύετε ότι τα prefixes που περιλαμβάνονται σε αυτά τα αρχεία δημιουργούν πρόβλημα στην περίπτωσή μας; Θυμηθείτε τα μειονεκτήματα του αλγορίθμου <b><i>Naive Bayes Classifier</i></b>. Τι θα μπορούσατε να κάνετε για να λύσετε το πρόβλημα αυτό (<a href=\"https://www.cs.cmu.edu/~tom/mlbook/NBayesLogReg.pdf\">https://www.cs.cmu.edu/~tom/mlbook/NBayesLogReg.pdf</a>);</li>\n",
    "<li>Μελετώντας τη συνάρτηση <i>find_prob()</i>, θα δείτε πως λείπουν οι πιθανότητες <i>prior</i> από τους υπολογισμούς. Τι παραδοχή έχουμε κάνει για τις <i>prior</i> πιθανότητες και κατά συνέπεια για τις δύο κατηγορίες ταξινόμησης (<i>valid</i>, <i>invalid</i>) στην άσκησή μας; Πώς αλλιώς θα μπορούσατε να τις επιλέξετε;</li>\n",
    "<li>Μπορείτε να προτείνετε κάποιο επιπρόσθετο <i>feature</i> για τον αλγόριθμο; (δε χρειάζεται να το υλοποιήσετε)</li>\n",
    "</ul>\n",
    "\n",
    "<p align=\"justify\"><b>Πηγές Δεδομένων</b></p>\n",
    "<ul>\n",
    "<li>Valid ονόματα: <a href=\"https://www.kaggle.com/cheedcheed/top1m\">https://www.kaggle.com/cheedcheed/top1m</a> (πολλά από τα κορυφαία σε επισκεψιμότητα site)</li>\n",
    "<li>Invalid ονόματα: Παράχθηκαν με το πρόγραμμα <a href=\"https://github.com/nkostopoulos/StochasticsLabPublic/blob/master/lab8/generator.py\">generator.py</a> που θα βρείτε μαζί με τα υπόλοιπα αρχεία της άσκησης.</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Η παραδοχή του αλγορίθμου είναι ότι τα χαρακτηριστικά εισόδου είναι ανεξάρτητα μεταξύ τους. Συνεπώς, αρκεί μια κατανομή για κάθε χαρακτηριστικό και καμία πληροφορία για την μεταξύ τους αλληλεξάρτηση άρα μειώνεται το πλήθος των παραμέτρων του μοντέλου (και προφανώς απλοποιείται η μαθηματική περιγραφή). Βασικό πλεονέκτημα του Naive Bayes Ταξινομητή είναι η πολύ απλή υλοποίηση, μιάς και για την ταξινόμηση ενός sample σε κάποια κλάση λαμβάνονται υπ'όψιν $d$ ($d$ πλήθος χαρακτηριστικών) παράμετροι. Για τον λόγο αυτό, ο συγκεκριμένος ταξινομητής τα πηγαίνει αρκετά καλά, ακόμα και όταν τα δεδομένα που έχουμε στην διάθεση μας είναι πολύ λίγα. Επιπρόσθετα, αναμένουμε η διαδικασία εκπαίδευσης του να είναι ιδιαίτερα απλή και γρήγορη, αφού πρακτικά απαιτείται ο υπολογισμός των αντίστοιχων πρότερων και δεσμευμένων πιθανοτήτων, μόνο.\n",
    "\n",
    "- Κάτω από την υπόθεση της στατιστικής ανεξαρτησίας μεταξύ των χαρακτηριστικών, ακόμα και εάν στην πράξη τις περισσότερες φορές δεν ισχύει, θεωρούμε ότι η ακόλουθη δεσμευμένη πιθανότητα παίρνει την εξής μορφή $p(\\textbf{x}| \\omega_i) = \\prod_{j = 1}^{d} p(\\textbf{x}_j | \\omega_i), i = 1, 2,...,M$, όπου $d$ το πλήθος των χαρακτηριστικών που έχουμε στην διάθεση μας, Μ οι πιθανές κλάσεις (στην συγκεκριμένη περίπτωση έχουμε Μ = 2) και $\\textbf{x}$ ένα δεδομένο διάνυσμα χαρακτηριστικών. Με βάση τον ταξινομητή Naive Bayes, ο οποίος αποτελεί την πιο απλή μορφή μπευζιανού ταξινομητή, ένα δεδομένο δείγμα $\\textbf{x}$ κατηγοριοποιείται στην κλάση $\\omega_m = argmax_{\\omega_i} p(\\omega_i)\\prod_{j = 1}^d p(\\textbf{x}_j|\\omega_i), i = 1,2,...,M$\n",
    "\n",
    "- Μελετώντας τα αρχεία valid_training.txt και invalid_training.txt, παρατηρούμε τα invalid prefixies χαρακτηρίζονται κατά κύριο λόγο από μεγάλο μήκος, μεγάλο αριθμό συμφώνων και αριθμών καθώς και από αρκετά συνεχόμενα σύμφωνα. Κάτι τέτοιο είναι όμως λογικό να συμβαίνει, μιάς και παράγονται με τυχαίο τρόπο.\n",
    "\n",
    "- Τα επτά χαρακτηριστικά που επιλέχθηκαν είναι:\n",
    "    - Μήκος του prefix\n",
    "    - Πλήθος ψηφίων\n",
    "    - Μήκος μεγαλύτερης ακολουθίας ψηφίων\n",
    "    - Πλήθος συμφώνων\n",
    "    - Μήκος μεγαλύτερης ακολουθίας συμφώνων\n",
    "    - Πλήθος φωνηέντων\n",
    "    - Μήκος μεγαλύτερης ακολουθίας φωνηέντων\n",
    "\n",
    "- Ο αλγόριθμος ταξινομεί περίπου 1.9% των valid ως invalid ενώ περίπου 1.2% των invalid ως valid. Ο χρόνος εκπαίδευσης είναι κάτι παραπάνω από 21 δευτερόλεπτα ενώ το μέγεθος του training test είναι 700 χιλιάδες ονόματα για κάθε μία από τις δύο κατηγορίες (1.400.000 δείγματα σύνολο).\n",
    "\n",
    "- Τα προβληματικά valid προκύπτουν είτε λόγω πολύ μικρών ονομάτων είτε λόγω συνένωσης των λέξεων με πάυλες. Για την επίλυση αυτού θα μπορούσαμε να επιτρέψουμε στον αλγόριθμο μέσω του training να αποδέχεται αντίστοιχα πολύ μικρά ονόματα, ενώ για το ζήτημα με τις παύλες θα μπορούσαμε να τις αγνοούμε κατά το διάβασμα. Το προβληματικό invalid δεν επιδέχεται κάποιας λύσης καθώς δεν υπάρχει κάτι προφανές να αντιληφθούμε, καθώς πρόκειται για εντελώς τυχαία ονοματοδοσία.\n",
    "\n",
    "- Μελετώντας την συνάρτηση $\\textit{find_prob()}$, παρατηρούμε ότι λείπουν εντελώς οι prior κατανομές των κλάσεων από τους υπολογισμούς. Αυτο συνεπάγεται ότι έχουμε θεωρήσει ισοπίθανες τις δύο κλάσεις στο σύνολο των δεδομένων εκπαίδευσης, καθώς στην συγκεκριμένη περίπτωση δεν επηρεάζουν το αποτελέσμα αν τους αφαιρέσουμε από τους υπολογισμούς. Διαφορετικά, η εκτίμηση για τις prior κατανομές κάθε κλάσης, είναι το ποσοστό των δειγμάτων εντός του train set που αντιστοιχεί στην εκάστοτε κλάση. Στην συγκεκριμένη περίπτωση οι δύο κλάσεις διαθέτουν ακριβώς το ίδιο πλήθος δειγμάτων στο train set, κάτι που συνεπάγεται ότι ακόμα και με την επιλογή του εναλλακτικού τρόπου προσέγγισμης των priors των δύο κλάσεων, θα καταλήγαμε ακριβώς στο ίδιο αποτέλσμα και ουσιαστικά θα τις αγνοούσαμε.\n",
    "\n",
    "- Παρατηρώντας προσεκτικά τις διαφορές των αρχείων που περιέχουν valid και invalid prefixes, διαπιστώνουμε ότι ένα άλλο πρόσθετο χαρακτηριστικό για ανίχνευση invalid prefixes από τον Naive Bayes ταξινομητή θα μπορούσε να είναι και ο συνόλικός αριθμός από dashes (-) εντός του prefix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O_plJQ1Z2i5M"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time needed: 21.13185709999999 seconds\n",
      "Valid names misclassified as invalid - Ratio:  1.9172947402180884\n",
      "Invalid names misclassified as valid - Ratio:  1.2655821677971868\n"
     ]
    }
   ],
   "source": [
    "from time import perf_counter\n",
    "problematic1 = open(\"problematic_valid.txt\", \"w\")\n",
    "problematic2 = open(\"problematic_invalid.txt\", \"w\")\n",
    "\n",
    "def load_file(file_name):\n",
    "    fd = open(file_name, \"r\")\n",
    "    my_set = set()\n",
    "    for prefix in fd:\n",
    "        prefix = prefix.rstrip()\n",
    "        my_set.add(prefix)\n",
    "    return my_set\n",
    "\n",
    "def calculate_probabilities(dataset):\n",
    "    stats = dict()\n",
    "    for index in range(0, 7):\n",
    "        stats[index] = dict()\n",
    "    for prefix in dataset:\n",
    "        features = handle_name(prefix)\n",
    "        for index in range(0, 7):\n",
    "            try:\n",
    "                stats[index][features[index]] += 1\n",
    "            except:\n",
    "                stats[index][features[index]] = 1\n",
    "\n",
    "    dataset_size = len(dataset)    \n",
    "    for index in range(0, 7):\n",
    "        for key in stats[index]:\n",
    "            stats[index][key] /= dataset_size\n",
    "    return stats\n",
    "\n",
    "def handle_name(prefix):\n",
    "    total_length = len(prefix)\n",
    "    total_digits, max_numeric_sequence = numeric(prefix)\n",
    "    total_consonants, max_consonants_sequence = consonants(prefix)\n",
    "    total_vowels, max_vowels_sequence = vowels(prefix)\n",
    "    return total_length, total_digits, max_numeric_sequence, total_consonants, max_consonants_sequence, total_vowels, max_vowels_sequence\n",
    "\n",
    "def vowels(prefix):\n",
    "    total_vowels = 0\n",
    "    vowels_sequence = list()\n",
    "    current_sequence = 0\n",
    "    for char in prefix:\n",
    "        if char == 'a' or char == 'e' or char == 'i' or char == 'o' or char == 'u':\n",
    "            total_vowels += 1\n",
    "            current_sequence += 1\n",
    "        else:\n",
    "            vowels_sequence.append(current_sequence)\n",
    "            current_sequence = 0\n",
    "    vowels_sequence.append(current_sequence)\n",
    "    max_vowels_sequence = max(vowels_sequence)\n",
    "    return total_vowels, max_vowels_sequence\n",
    "\n",
    "def consonants(prefix):\n",
    "    total_consonants = 0\n",
    "    consonants_sequence = list()\n",
    "    current_sequence = 0\n",
    "    for char in prefix:\n",
    "        if char != 'a' and char != 'e' and char != 'i' and char != 'o' and char != 'u' and char != '-' and char.isdigit() == False:\n",
    "            total_consonants += 1\n",
    "            current_sequence += 1\n",
    "        else:\n",
    "            consonants_sequence.append(current_sequence)\n",
    "            current_sequence = 0\n",
    "    consonants_sequence.append(current_sequence)\n",
    "    max_consonants_sequence = max(consonants_sequence)\n",
    "    return total_consonants, max_consonants_sequence\n",
    "\n",
    "def numeric(prefix):\n",
    "    total_digits = 0\n",
    "    numeric_sequence = list()\n",
    "    current_sequence = 0\n",
    "    for char in prefix:\n",
    "        if char.isdigit() == True:\n",
    "            total_digits += 1\n",
    "            current_sequence += 1\n",
    "        else:\n",
    "            numeric_sequence.append(current_sequence)\n",
    "            current_sequence = 0\n",
    "    numeric_sequence.append(current_sequence)\n",
    "    max_numeric_sequence = max(numeric_sequence)\n",
    "    return total_digits, max_numeric_sequence\n",
    "            \n",
    "def find_prob(prefix, stats, fd):\n",
    "    tl, td, mns, tc, mcs, tv, mvs = handle_name(prefix)\n",
    "    try:\n",
    "        prob = stats[0][tl] * stats[1][td] * stats[2][mns] * stats[3][tc] * stats[4][mcs] * stats[5][tv] * stats[6][mvs]\n",
    "    except:\n",
    "        prob = 0\n",
    "        fd.write(prefix + \"\\n\")\n",
    "    return prob\n",
    "\n",
    "def apply_on_test_set(test_set, category, valid_stats, invalid_stats, fd):\n",
    "    misclassifications = 0\n",
    "    names_processed = 0\n",
    "    for prefix in test_set:\n",
    "        valid_prob = find_prob(prefix, valid_stats, fd)\n",
    "        invalid_prob = find_prob(prefix, invalid_stats, fd)\n",
    "        if valid_prob != 0 and invalid_prob != 0:\n",
    "            names_processed += 1\n",
    "            if category == \"valid\" and valid_prob < invalid_prob:\n",
    "                misclassifications += 1\n",
    "            elif category == \"invalid\" and valid_prob > invalid_prob:\n",
    "                misclassifications += 1\n",
    "    return misclassifications, names_processed\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load valid names training set\n",
    "    valid_names_training = load_file(\"./valid_training.txt\")\n",
    "    # Load valid names test set\n",
    "    valid_names_test = load_file(\"./valid_test.txt\")\n",
    "    # Load invalid names training set\n",
    "    invalid_names_training = load_file(\"./invalid_training.txt\")\n",
    "    # Load invalid names test set\n",
    "    invalid_names_test = load_file(\"./invalid_test.txt\")\n",
    "    \n",
    "    start = perf_counter()\n",
    "    valid_stats = calculate_probabilities(valid_names_training)\n",
    "    invalid_stats = calculate_probabilities(invalid_names_training)\n",
    "    end = perf_counter()\n",
    "    print(\"Training time needed: {} seconds\".format(end - start))\n",
    "\n",
    "    valid_misclassifications, valid_names_processed = apply_on_test_set(valid_names_test, \"valid\", valid_stats, invalid_stats, problematic1)\n",
    "    invalid_misclassifications, invalid_names_processed = apply_on_test_set(invalid_names_test, \"invalid\", valid_stats, invalid_stats, problematic2)\n",
    "\n",
    "    print(\"Valid names misclassified as invalid - Ratio: \", (valid_misclassifications / valid_names_processed) * 100)\n",
    "    print(\"Invalid names misclassified as valid - Ratio: \", (invalid_misclassifications / invalid_names_processed) * 100)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Stochastic_Processes_&_Optimization_in_Machine_Learning_(Lab_8_DNS_Water_Torture).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
